{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Comitê de Máquinas de Aprendizado (Ensemble Learning)</h1>\n",
    "<p style=\"font-size:16px\">Consiste da fusão de várias máquinas de aprendizado objetivando melhorar a capacidade de generalização da IA.</p>\n",
    "<br>\n",
    "<img src=\"img/ComiteMaquinasGeral.png\" width=\"80%\">\n",
    "\n",
    "<p style=\"font-size:16px\">A técnica de <b>Comitê de Máquinas</b> é baseada no conceito de <b>diversidade</b></p>. <br>\n",
    "<h3>Abordagens (Diversificação)</h3>\n",
    "<p style=\"font-size:16px\">\n",
    "Existem algumas abordagens para obter diversidade:\n",
    "<ul style=\"font-size:16px\">\n",
    "    <li>Subamostragem do espaço de entrada. Exemplo: seleção de conjuntos de dados com alguma intersecção.</li>\n",
    "    <li>Subamostragem dos atributos. Exemplo: utilizar atributos com mesma característica.</li>\n",
    "    <li>Configuração dos hiper-parâmetros dos modelos. Exemplo: número de iterações, tolerância, número de camadas ocultas, etc.</li>\n",
    "    <li>Utilização de distintos algoritmos. Exemplo: Redes Neurais, Árvores de Decisão, KNN, etc.</li>\n",
    "</ul>\n",
    "</p>\n",
    "<h3>Métodos (Combinador Linear)</h3>\n",
    "<p style=\"font-size:16px\">\n",
    "    Para <b>combinar (fundir)</b> as predições utilizamos <b>voto majoritário</b>, para o qual há basicamente dois modos de implementação: <em>hard</em> e <em>soft</em>, os quais são baseados nos discriminantes $\\Delta_{qc}$ onde $q=1, 2, \\cdots, Q$ indexa as máquinas, e $c=1,2,\\cdots,C$ indexa as classes do conjunto $\\Lambda = \\lbrace \\lambda_1, \\lambda_2, \\cdots, \\lambda_C \\rbrace$. Portanto, para uma classe fixa $\\lambda_K$, com $K=1,2,\\cdots,C$, o discriminante fornece<br><br>\n",
    "$$\n",
    "\\Delta_{qK}(\\mathbf{x}_n) = \\left \\lbrace\n",
    "        \\begin{array}{rl}\n",
    "        1, & \\textrm{ se } h_q(\\mathbf{x}_n, \\beta) = \\lambda_K\\\\\n",
    "        0, & \\textrm{ caso contrário }\n",
    "        \\end{array}\n",
    "        \\right. , ~~ q=1, 2, \\cdots, Q\n",
    "$$\n",
    "<br>\n",
    "onde $h_q(\\mathbf{x}_n, \\beta)$ é um modelo ajutado com os parâmetros $\\beta$ na etapa de treinamento.<br><br>\n",
    "Assim, a classe ${\\lambda} \\in \\Lambda$ é predita considerando os pesos (importância) de cada máquina $w_q$:\n",
    "<ul style=\"font-size:16px\">\n",
    "    <li><em><b>HARD</b></em> que utiliza a quantidade de predições corretas<br><br>\n",
    "        $$\n",
    "        {\\lambda_h} = \\textrm{argmax}_{\\lambda_K \\in \\Lambda} \\left\\lbrace \\sum_{q=1}^{Q} w_q \\Delta_{qK}(\\mathbf{x}_n) \\right\\rbrace\n",
    "        $$\n",
    "        <br><br>\n",
    "        <b>Exemplo</b>. Predições para o padrão $\\mathbf{x}_n$, com $Q=3$, $C=2$ e $w_q = 1, \\forall q$:\n",
    "        <table>\n",
    "            <tr><td>Máquina</td><td>1</td><td>2</td><td>3</td></tr>\n",
    "            <tr><td>Classe</td><td>$\\lambda_2$</td><td>$\\lambda_2$</td><td>$\\lambda_1$</td></tr>\n",
    "        </table><br>\n",
    "        Para a classe $\\lambda_1$ ($K=1$) temos:\n",
    "        $$\n",
    "        \\sum_{q=1}^{3} \\Delta_{q1}(\\mathbf{x}_n) = \\Delta_{11}(\\mathbf{x}_n) + \\Delta_{21}(\\mathbf{x}_n) + \\Delta_{31}(\\mathbf{x}_n) = 0 + 0 + 1 = 1\n",
    "        $$\n",
    "        <br>\n",
    "        Para a classe $\\lambda_2$ ($K=2$) temos:\n",
    "        $$\n",
    "        \\sum_{q=1}^{3} \\Delta_{q2}(\\mathbf{x}_n) = \\Delta_{12}(\\mathbf{x}_n) + \\Delta_{22}(\\mathbf{x}_n) + \\Delta_{32}(\\mathbf{x}_n) = 1 + 1 + 0 = 2\n",
    "        $$\n",
    "        <br>\n",
    "        Portanto,\n",
    "        $$\n",
    "        \\max \\lbrace \\sum_{q=1}^{3} \\Delta_{q1}(\\mathbf{x}_n),  \\sum_{q=1}^{3} \\Delta_{q2}(\\mathbf{x}_n) \\rbrace = 2\n",
    "        $$\n",
    "        <br>\n",
    "        logo, o índice $K$ que retorna o máximo é $K=2$, portanto a classe predita é $\\lambda = \\lambda_2$.\n",
    "    </li><br><hr>\n",
    "    <li><em><b>SOFT</b></em> que emprega as probabilidades.<br><br>\n",
    "    $$\n",
    "    {\\lambda_s} = \\textrm{argmax}_{\\lambda_K \\in \\Lambda} \\left\\lbrace \\sum_{q=1}^{Q} w_q p_q(\\mathbf{x}_n|\\lambda_K) \\right\\rbrace\n",
    "    $$<br>\n",
    "        onde $p_q(\\mathbf{x}_n|\\lambda_K)$ é a probabilidade da $q$-ésima máquina predizer o valor $\\lambda_K$ dado o padrão $\\mathbf{x}_n$.<br><br>\n",
    "        <b>Exemplo</b>. Predições para o padrão $\\mathbf{x}_m$, com $Q=3$, $C=2$ e $w_q = 1, \\forall q$:\n",
    "        <table>\n",
    "            <tr><td>Máquina</td><td>1</td><td>2</td><td>3</td></tr>\n",
    "            <tr><td>Classe</td><td>$\\lambda_2$</td><td>$\\lambda_2$</td><td>$\\lambda_1$</td></tr>\n",
    "            <tr><td>Probabilidade</td><td>0,7</td><td>0,6</td><td>0,9</td></tr>\n",
    "        </table><br>\n",
    "        Para a classe $\\lambda_1$ ($K=1$) temos:\n",
    "        $$\n",
    "        \\sum_{q=1}^{3} p_q(\\mathbf{x}_m|\\lambda_1) = p_1(\\mathbf{x}_m|\\lambda_1) + p_2(\\mathbf{x}_m|\\lambda_1) + p_3(\\mathbf{x}_m|\\lambda_1) = 0,3 + 0,4 + 0,9 = 1,6\n",
    "        $$\n",
    "        <br>\n",
    "        Para a classe $\\lambda_2$ ($K=2$) temos:\n",
    "        $$\n",
    "        \\sum_{q=1}^{3} p_q(\\mathbf{x}_m|\\lambda_2) = p_1(\\mathbf{x}_m|\\lambda_2) + p_2(\\mathbf{x}_m|\\lambda_2) + p_3(\\mathbf{x}_m|\\lambda_2) = 0,7 + 0,6 + 0,1 = 1,4\n",
    "        $$\n",
    "        <br>\n",
    "        Portanto,\n",
    "        $$\n",
    "        \\max \\lbrace \\sum_{q=1}^{3} p_q(\\mathbf{x}_m|\\lambda_1),  \\sum_{q=1}^{3} p_q(\\mathbf{x}_m|\\lambda_2) \\rbrace = 1,6\n",
    "        $$\n",
    "        <br>\n",
    "        logo, o índice $K$ que retorna o máximo é $K=1$, portanto a classe predita é $\\lambda = \\lambda_1$.\n",
    "    </li>\n",
    "</ul>\n",
    "</p>\n",
    "<br>\n",
    "<h3>Exemplo 1</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo 1 (Comitê com 3 máquinas): Subamostragem do espaço de entrada\n",
      "\n",
      "Completo\n",
      "    Acc: 94.7368% F1: 95.8525%\n",
      "Individuais\n",
      "M1  Acc: 93.5673% F1: 95.0226%\n",
      "M2  Acc: 92.3977% F1: 93.8967%\n",
      "M3  Acc: 92.9825% F1: 94.3925%\n",
      "Comitê Hard\n",
      "    Acc: 93.5673% F1: 94.8837%\n",
      "Comitê Soft\n",
      "    Acc: 93.5673% F1: 94.8837%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Exemplo 1: Cada máquina será treinada utilizando dintintas intâncias\n",
    "'''\n",
    "print('Exemplo 1 (Comitê com 3 máquinas): Subamostragem do espaço de entrada\\n')\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from mlxtend.classifier import EnsembleVoteClassifier # pip install mlxtend\n",
    "    \n",
    "def avalia(y_true, y_pred, label):\n",
    "    F   = f1_score(y_true, y_pred)\n",
    "    Acc = accuracy_score(y_true, y_pred)\n",
    "    print((label + '  Acc: {:.4f}%' + ' F1: {:.4f}%').format(Acc * 100, F * 100))\n",
    "    \n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True) #Carrega dos dados da dataset sobre Câncer de Mama (569 x 30)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) #separa em dados de treino e teste\n",
    "\n",
    "'''\n",
    "Cria uma base de dados para treinamento de cada máquina\n",
    "'''\n",
    "N_train = int(X_train.shape[0]/3) #Número de instâncias para treinamento que cada máquina receberá\n",
    "\n",
    "X_train1 = X_train[:N_train, :]           #Instâncias para treinar a máquina 1 (132 x 30)\n",
    "y_train1 = y_train[:N_train]\n",
    "X_train2 = X_train[N_train:2*N_train, :]  #Instâncias para treinar a máquina 2 (132 x 30)\n",
    "y_train2 = y_train[N_train:2*N_train]\n",
    "X_train3 = X_train[2*N_train:, :]         #Instâncias para treinar a máquina 3 (134 x 30)\n",
    "y_train3 = y_train[2*N_train:]\n",
    "\n",
    "'''\n",
    "Treina uma máquina com o conjunto completo, apenas para comperação, pois esta não será empregada no comitê\n",
    "'''\n",
    "print('Completo')\n",
    "\n",
    "M0 = GaussianNB().fit(X_train, y_train)\n",
    "yhat_M0 = M0.predict(X_test)\n",
    "avalia(y_test, yhat_M0, '  ')\n",
    "\n",
    "'''\n",
    "Treina três máquinas de aprendizado com distintos conjuntos de entrada\n",
    "'''\n",
    "print('Individuais')\n",
    "\n",
    "M1 = GaussianNB().fit(X_train1, y_train1)\n",
    "yhat_M1 = M1.predict(X_test)\n",
    "avalia(y_test, yhat_M1, 'M1')\n",
    "\n",
    "M2 = GaussianNB().fit(X_train2, y_train2)\n",
    "yhat_M2 = M2.predict(X_test)\n",
    "avalia(y_test, yhat_M2, 'M2')\n",
    "\n",
    "M3 = GaussianNB().fit(X_train3, y_train3)\n",
    "yhat_M3 = M3.predict(X_test)\n",
    "avalia(y_test, yhat_M3, 'M3')\n",
    "\n",
    "'''\n",
    "Implementa o comitê de máquinas\n",
    "'''\n",
    "print('Comitê Hard')\n",
    "ComiteH = EnsembleVoteClassifier(clfs=[M1, M2, M3], weights=[1, 1, 1], voting='hard', refit=False).fit(X_test, y_test)\n",
    "yhat   = ComiteH.predict(X_test)\n",
    "avalia(y_test, yhat, '  ')\n",
    "\n",
    "print('Comitê Soft')\n",
    "ComiteS = EnsembleVoteClassifier(clfs=[M1, M2, M3], weights=[1, 1, 1], voting='soft', refit=False).fit(X_test, y_test)\n",
    "yhat   = ComiteS.predict(X_test)\n",
    "avalia(y_test, yhat, '  ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exemplo 2</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo 2 (Comitê com 3 máquinas): Subamostragem do espaço de atributos\n",
      "\n",
      "Individuais\n",
      "M1  Acc: 90.0585% F1: 92.2374%\n",
      "M2  Acc: 80.7018% F1: 85.8369%\n",
      "M3  Acc: 94.1520% F1: 95.4128%\n",
      "Comitê Hard  Acc: 92.9825% F1: 94.5455%\n",
      "Comitê Soft  Acc: 92.9825% F1: 94.5455%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Exemplo 2: Cada máquina será treinada utilizando dintintas conjuntos de atributos\n",
    "'''\n",
    "print('Exemplo 2 (Comitê com 3 máquinas): Subamostragem do espaço de atributos\\n')\n",
    "\n",
    "'''\n",
    "Cria uma base de dados para treinamento de cada máquina\n",
    "'''\n",
    "M = int(X_train.shape[1]/3) #Número de atributos para treinamento de cada máquina\n",
    "\n",
    "X2_train1 = X_train[:,:M]     #Instâncias para treinar a máquina 1 (569 x 10)\n",
    "X2_train2 = X_train[:, M:2*M] #Instâncias para treinar a máquina 2 (569 x 10)\n",
    "X2_train3 = X_train[:,2*M:]   #Instâncias para treinar a máquina 3 (569 x 10)\n",
    "\n",
    "'''\n",
    "Neste caso também é necessário particionar o conjunto de teste\n",
    "'''\n",
    "X2_test1 = X_test[:,:M]     #Instâncias para treinar a máquina 1 (569 x 10)\n",
    "X2_test2 = X_test[:, M:2*M] #Instâncias para treinar a máquina 2 (569 x 10)\n",
    "X2_test3 = X_test[:,2*M:]   #Instâncias para treinar a máquina 3 (569 x 10)\n",
    "\n",
    "'''\n",
    "Treina três máquinas de aprendizado com distintos conjuntos de entrada\n",
    "'''\n",
    "print('Individuais')\n",
    "\n",
    "M1 = GaussianNB().fit(X2_train1, y_train)\n",
    "yhat_M1   = M1.predict(X2_test1)\n",
    "yhat_M1_p = M1.predict_proba(X2_test1)\n",
    "avalia(y_test, yhat_M1, 'M1')\n",
    "\n",
    "M2 = GaussianNB().fit(X2_train2, y_train)\n",
    "yhat_M2   = M2.predict(X2_test2)\n",
    "yhat_M2_p = M2.predict_proba(X2_test2)\n",
    "avalia(y_test, yhat_M2, 'M2')\n",
    "\n",
    "M3 = GaussianNB().fit(X2_train3, y_train)\n",
    "yhat_M3   = M3.predict(X2_test3)\n",
    "yhat_M3_p = M3.predict_proba(X2_test3)\n",
    "avalia(y_test, yhat_M3, 'M3')\n",
    "\n",
    "'''\n",
    "Implementa o comitê de máquinas\n",
    "'''\n",
    "def delta(y, y_hat):\n",
    "    if y == y_hat:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "ypredH_comite = [] #armazena as predições do comitê hard\n",
    "for i in range(0, len(yhat_M1)):\n",
    "    \n",
    "    preds = np.zeros(2)\n",
    "    preds[0] = np.sum(np.array([delta(0, yhat_M1[i]), delta(0, yhat_M2[i]), delta(0, yhat_M3[i])]))\n",
    "    preds[1] = np.sum(np.array([delta(1, yhat_M1[i]), delta(1, yhat_M2[i]), delta(1, yhat_M3[i])]))\n",
    "    \n",
    "    ypred_comite = np.argmax(preds)\n",
    "    \n",
    "    ypredH_comite.append(ypred_comite)\n",
    "    \n",
    "avalia(y_test, ypredH_comite, 'Comitê Hard')\n",
    "\n",
    "ypredS_comite = [] #armazena as predições do comitê soft\n",
    "for i in range(0, len(yhat_M1_p)):\n",
    "    \n",
    "    p = np.sum(np.array([yhat_M1_p[i], yhat_M2_p[i], yhat_M3_p[i]]), axis=0)\n",
    "    preds    = np.zeros(2)\n",
    "    preds[0] = p[0]\n",
    "    preds[1] = p[1]\n",
    "    \n",
    "    ypred_comite = np.argmax(preds)\n",
    "    \n",
    "    ypredS_comite.append(ypred_comite)\n",
    "    \n",
    "avalia(y_test, ypredS_comite, 'Comitê Soft')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Exemplo 3</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo 3 (Comitê com 3 máquinas): Distintos hiper-parâmetros\n",
      "\n",
      "Individual\n",
      "    Acc: 92.9825% F1: 94.4954%\n",
      "    Acc: 92.9825% F1: 94.5455%\n",
      "    Acc: 92.9825% F1: 94.5946%\n",
      "Comitê Hard\n",
      "    Acc: 93.5673% F1: 95.0226%\n",
      "Comitê Soft\n",
      "    Acc: 94.1520% F1: 95.4545%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Exemplo 3: Cada máquina será treinada utilizando distintos hiper-parâmetros das máquinas KNN\n",
    "'''\n",
    "print('Exemplo 3 (Comitê com 3 máquinas): Distintos hiper-parâmetros\\n')\n",
    "\n",
    "print('Individual')\n",
    "\n",
    "M1 = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\n",
    "yhat_M1 = M1.predict(X_test)\n",
    "avalia(y_test, yhat_M1, '  ')\n",
    "\n",
    "M2 = KNeighborsClassifier(n_neighbors=10).fit(X_train, y_train)\n",
    "yhat_M2 = M2.predict(X_test)\n",
    "avalia(y_test, yhat_M2, '  ')\n",
    "\n",
    "M3 = KNeighborsClassifier(n_neighbors=15).fit(X_train, y_train)\n",
    "yhat_M3 = M3.predict(X_test)\n",
    "avalia(y_test, yhat_M3, '  ')\n",
    "\n",
    "'''\n",
    "Implementa o comitê de máquinas\n",
    "'''\n",
    "print('Comitê Hard')\n",
    "ComiteH = EnsembleVoteClassifier(clfs=[M1, M2, M3], weights=[1, 1, 1], voting='hard', refit=False).fit(X_test, y_test)\n",
    "yhat   = ComiteH.predict(X_test)\n",
    "avalia(y_test, yhat, '  ')\n",
    "\n",
    "print('Comitê Soft')\n",
    "ComiteS = EnsembleVoteClassifier(clfs=[M1, M2, M3], weights=[1, 1, 1], voting='soft', refit=False).fit(X_test, y_test)\n",
    "yhat   = ComiteS.predict(X_test)\n",
    "avalia(y_test, yhat, '  ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pesos das máquinas</h3>\n",
    "<p style=\"font-size:16px\">Há várias abordagens para obtenção dos pesos, sendo a mais simples baseada na acurácia de cada máquina. Seja $A_z$ a acurácia da $z$-ésima máquina. Então $w_z$ é dado por<br>\n",
    "$$\n",
    "w_z = \\dfrac{A_z}{\\sum_{q=1}^{Q} A_q}\n",
    "$$\n",
    "</p>\n",
    "<br>\n",
    "<p style=\"font-size:16px\"><b>Exemplo</b>. Acurácias ($A_z$) e pesos respectivos ($w_z$) para um padrão qualquer, com $Q=3$ onde $\\sum_{q=1}^{3} A_q = \\textrm{2,4}$\n",
    "        <table>\n",
    "            <tr><td>Máquina</td><td>1</td><td>2</td><td>3</td></tr>\n",
    "            <tr><td>Acurácia</td><td>0.8</td><td>0.7</td><td>0.9</td></tr>\n",
    "            <tr><td>Peso</td><td>0.330</td><td>0.290</td><td>0.375</td></tr>\n",
    "            <tr><td>Classe</td><td>$\\lambda_2$</td><td>$\\lambda_2$</td><td>$\\lambda_1$</td></tr>\n",
    "            <tr><td>Probabilidade</td><td>0.7</td><td>0.6</td><td>0.9</td></tr>\n",
    "        </table><br></p><p style=\"font-size:16px\">\n",
    "        Para a classe $\\lambda_1$ ($K=1$) temos:\n",
    "        $$\n",
    "        \\sum_{q=1}^{3} w_q p_q(\\mathbf{x}_m|\\lambda_1) = w_1 p_1(\\mathbf{x}_m|\\lambda_1) + w_2 p_2(\\mathbf{x}_m|\\lambda_1) + w_3 p_3(\\mathbf{x}_m|\\lambda_1) = 0.333 \\cdot 0.3 + 0.290 \\cdot 0.4 + 0.375 \\cdot 0.9 = 0.5534\n",
    "        $$\n",
    "        <br>\n",
    "        Para a classe $\\lambda_2$ ($K=2$) temos:\n",
    "        $$\n",
    "        \\sum_{q=1}^{3} w_q p_q(\\mathbf{x}_m|\\lambda_2) = w_1 p_1(\\mathbf{x}_m|\\lambda_2) + w_2 p_2(\\mathbf{x}_m|\\lambda_2) + w_3 p_3(\\mathbf{x}_m|\\lambda_2) = 0.333 \\cdot 0.7 + 0.290 \\cdot 0.6 + 0.375 \\cdot  0.1 = 0.4446\n",
    "        $$\n",
    "        <br>\n",
    "        Portanto,\n",
    "        $$\n",
    "        \\max \\lbrace \\sum_{q=1}^{3} w_q p_q(\\mathbf{x}_m|\\lambda_1),  \\sum_{q=1}^{3} w_q p_q(\\mathbf{x}_m|\\lambda_2) \\rbrace = 0.5534\n",
    "        $$\n",
    "        <br>\n",
    "        logo, o índice $K$ que retorna o máximo é $K=1$, portanto a classe predita é $\\lambda = \\lambda_1$.\n",
    "</p>\n",
    "<h3>Exemplo 4</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemplo 4 (Comitê com 3 máquinas): Utilização do peso de cada máquina\n",
      "\n",
      "Individual\n",
      "M1  Acc: 92.9825% F1: 94.4954%\n",
      "M2  Acc: 92.3977% F1: 94.1704%\n",
      "M3  Acc: 91.2281% F1: 93.2735%\n",
      "Comitê Hard\n",
      "    Acc: 92.9825% F1: 94.5455%\n",
      "\n",
      "Pesos calculados\n",
      "Máquina 1 0.3362\n",
      "Máquina 2 0.3340\n",
      "Máquina 3 0.3298\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Comitê de máquinas utilizando o peso (importância) de cada máquina\n",
    "'''\n",
    "print('Exemplo 4 (Comitê com 3 máquinas): Utilização do peso de cada máquina\\n')\n",
    "\n",
    "print('Individual')\n",
    "\n",
    "M1 = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\n",
    "yhat_M1 = M1.predict(X_test)\n",
    "avalia(y_test, yhat_M1, 'M1')\n",
    "\n",
    "M2 = Perceptron().fit(X_train, y_train)\n",
    "yhat_M2 = M2.predict(X_test)\n",
    "avalia(y_test, yhat_M2, 'M2')\n",
    "\n",
    "M3 = KNeighborsClassifier(n_neighbors=25).fit(X_train, y_train)\n",
    "yhat_M3 = M3.predict(X_test)\n",
    "avalia(y_test, yhat_M3, 'M3')\n",
    "\n",
    "'''\n",
    "Calculo o peso de cada máquina\n",
    "'''\n",
    "Acc_M1 = accuracy_score(y_test, yhat_M1) #acurácia máquina 1\n",
    "Acc_M2 = accuracy_score(y_test, yhat_M2) #acurácia máquina 2\n",
    "Acc_M3 = accuracy_score(y_test, yhat_M3) #acurácia máquina 3\n",
    "\n",
    "Acc_T = Acc_M1 + Acc_M2 + Acc_M3 #acurácia total\n",
    "\n",
    "w1 = Acc_M1/Acc_T #Peso da máquina 1\n",
    "w2 = Acc_M2/Acc_T #Peso da máquina 2\n",
    "w3 = Acc_M3/Acc_T #Peso da máquina 3\n",
    "\n",
    "W = [w1, w2, w3] #vetor de pesos\n",
    "\n",
    "'''\n",
    "Implementa o comitê de máquinas\n",
    "'''\n",
    "print('Comitê Hard')\n",
    "ComiteH = EnsembleVoteClassifier(clfs=[M1, M2, M3], weights=W, voting='hard', refit=False).fit(X_test, y_test)\n",
    "yhat   = ComiteH.predict(X_test)\n",
    "avalia(y_test, yhat, '  ')\n",
    "\n",
    "print('\\nPesos calculados')\n",
    "print(('Máquina 1 {:.4f}').format(w1))\n",
    "print(('Máquina 2 {:.4f}').format(w2))\n",
    "print(('Máquina 3 {:.4f}').format(w3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Referências</h3>\n",
    "<ul style=\"font-size:16px\">\n",
    "    <li>Ditterrich, T., 1997. Machine learning research: four current direction. Artificial intelligence magazine 4, 97–136.</li>\n",
    "    <li>Polikar, R., 2006. Ensemble based systems in decision making, volume 6, 21–45.\n",
    "        doi:10.1109/MCAS.2006.1688199</li>\n",
    "    <li>Raschka, S., 2018. Mlxtend: Providing machine learning and data science utilities and extensions to python’s scientific computing stack 3. doi:10.21105/joss.00638.</li>\n",
    "    <li>Rokach, L., 2010. Pattern Classification using Ensemble Learning. volume 75 of Series in Machine Perception and Artificial Intelligence. New Jersey.</li>\n",
    "    <li>Sagi, O., Rokach, L., 2018. Ensemble learning: A survey. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 8, e1249.</li>\n",
    "    <li>Oliveira, B.R.d., Abreu, C.C.E.d., Duarte, M.A.Q., Vieira Filho, J., 2019. Geometrical features for premature ventricular contraction recognition with analytic hierarchy process based machine learning algorithms selection,59–69 doi:10.1016/j.cmpb.2018.12.028.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
